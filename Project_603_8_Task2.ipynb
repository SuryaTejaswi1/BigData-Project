{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2:\n",
    "\n",
    "####  Objective: Perform Sector and Subsector level analysis and Identify the sources/ assets resposible for the emissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiating Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark-3.2.4-bin-hadoop2.7\\\\spark-3.2.4-bin-hadoop2.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark job user: Surya\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Check_User\").getOrCreate()\n",
    "\n",
    "# Get the user running the Spark job\n",
    "user = spark.sparkContext.sparkUser()\n",
    "print(\"Spark job user:\", user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import input_file_name\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, DoubleType,IntegerType\n",
    "\n",
    "import os\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"Task2\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema for the provided data\n",
    "schema_ownership = StructType([\n",
    "    StructField(\"asset_id\", StringType(), True),\n",
    "    StructField(\"asset_name\", StringType(), True),\n",
    "    StructField(\"owner_name\", StringType(), True),\n",
    "    StructField(\"owner_classification\", StringType(), True),\n",
    "    StructField(\"percentage_of_ownership\", StringType(), True),\n",
    "    StructField(\"owner_direct_parent\", StringType(), True),\n",
    "    StructField(\"owner_grouping\", StringType(), True),\n",
    "    StructField(\"operator_name\", StringType(), True),\n",
    "    StructField(\"percentage_of_operation\", StringType(), True),\n",
    "    StructField(\"data_source\", StringType(), True),\n",
    "    StructField(\"url\", StringType(), True),\n",
    "    StructField(\"recency\", TimestampType(), True),\n",
    "    StructField(\"created_date\", StringType(), True),\n",
    "    StructField(\"original_inventory_sector\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdfs import InsecureClient\n",
    "\n",
    "# Define the directory path in HDFS\n",
    "hdfs_directory = '/user/username/project_data/Data/'\n",
    "\n",
    "# Define the HDFS path\n",
    "hdfs_path = \"hdfs://localhost:9000/user/username/project_data/Data/\"\n",
    "\n",
    "\n",
    "#Method to obtain the file_names\n",
    "\n",
    "def obtain_file_names(folder_path):\n",
    "    try:\n",
    "        # Initialize HDFS client\n",
    "        client = InsecureClient('http://localhost:50070', user='surya') \n",
    "        # List files in the directory\n",
    "        file_names = client.list(folder_path)\n",
    "        return file_names\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return print(f\"Error executing command: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The below code will create a data frame which stores the file names, type of the file namely, emission and ownership files and their respective HDFS paths.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "folders = [\"agriculture\", \"buildings\", \"fluorinated_gases\", \"fossil_fuel_operations\", \n",
    "           \"manufacturing\", \"mineral_extraction\", \"power\", \"waste\"] \n",
    "\n",
    "# Define the schema for the DataFrame\n",
    "schema_1 = StructType([\n",
    "    StructField(\"folder\", StringType(), True),\n",
    "    StructField(\"file_type\", StringType(), True),\n",
    "    StructField(\"file_name\", StringType(), True),\n",
    "    StructField(\"file_path\", StringType(), True)  # Adding the file_path column\n",
    "])\n",
    "\n",
    "# List to store all rows\n",
    "all_rows = []\n",
    "\n",
    "for folder in folders:\n",
    "    folder_dir_path = os.path.join(hdfs_directory, folder)\n",
    "    file_names = obtain_file_names(folder_dir_path)\n",
    "    #print(folder, folder_dir_path, file_names, '\\n')\n",
    "    \n",
    "    # Filter file paths for emissions and ownership files\n",
    "    emission_files = [name for name in file_names if name.startswith('asset_') and name.endswith('_emissions.csv')]\n",
    "    ownership_files = [name for name in file_names if name.startswith('asset_') and name.endswith('_ownership.csv')]\n",
    "    \n",
    "    # Collect data for emission and ownership files in the list\n",
    "    all_rows.extend([Row(folder, 'emission_files', name, f\"hdfs://localhost:9000{folder_dir_path}/{name}\") for name in emission_files])\n",
    "    all_rows.extend([Row(folder, 'ownership_files', name, f\"hdfs://localhost:9000{folder_dir_path}/{name}\") for name in ownership_files])\n",
    "\n",
    "# Create DataFrame from the collected rows\n",
    "all_files_df = spark.createDataFrame(all_rows, schema_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+--------------------+--------------------+\n",
      "|              folder|      file_type|           file_name|           file_path|\n",
      "+--------------------+---------------+--------------------+--------------------+\n",
      "|         agriculture| emission_files|asset_cropland-fi...|hdfs://localhost:...|\n",
      "|         agriculture| emission_files|asset_enteric-fer...|hdfs://localhost:...|\n",
      "|         agriculture| emission_files|asset_manure-mana...|hdfs://localhost:...|\n",
      "|         agriculture| emission_files|asset_synthetic-f...|hdfs://localhost:...|\n",
      "|         agriculture|ownership_files|asset_enteric-fer...|hdfs://localhost:...|\n",
      "|         agriculture|ownership_files|asset_manure-mana...|hdfs://localhost:...|\n",
      "|fossil_fuel_opera...| emission_files|asset_coal-mining...|hdfs://localhost:...|\n",
      "|fossil_fuel_opera...| emission_files|asset_oil-and-gas...|hdfs://localhost:...|\n",
      "|fossil_fuel_opera...| emission_files|asset_oil-and-gas...|hdfs://localhost:...|\n",
      "|fossil_fuel_opera...|ownership_files|asset_oil-and-gas...|hdfs://localhost:...|\n",
      "|fossil_fuel_opera...|ownership_files|asset_oil-and-gas...|hdfs://localhost:...|\n",
      "|       manufacturing| emission_files|asset_aluminum_em...|hdfs://localhost:...|\n",
      "|       manufacturing| emission_files|asset_cement_emis...|hdfs://localhost:...|\n",
      "|       manufacturing| emission_files|asset_pulp-and-pa...|hdfs://localhost:...|\n",
      "|       manufacturing| emission_files|asset_steel_emiss...|hdfs://localhost:...|\n",
      "|       manufacturing|ownership_files|asset_cement_owne...|hdfs://localhost:...|\n",
      "|       manufacturing|ownership_files|asset_pulp-and-pa...|hdfs://localhost:...|\n",
      "|       manufacturing|ownership_files|asset_steel_owner...|hdfs://localhost:...|\n",
      "|  mineral_extraction| emission_files|asset_bauxite-min...|hdfs://localhost:...|\n",
      "|  mineral_extraction| emission_files|asset_copper-mini...|hdfs://localhost:...|\n",
      "+--------------------+---------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_files_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Create a dictionary by merging all the individual emission and ownership files for each sector</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Name: agriculture_emission_df\n",
      "DataFrame Name: agriculture_ownership_df\n",
      "DataFrame Name: fossil_fuel_operations_emission_df\n",
      "DataFrame Name: fossil_fuel_operations_ownership_df\n",
      "DataFrame Name: manufacturing_emission_df\n",
      "DataFrame Name: manufacturing_ownership_df\n",
      "DataFrame Name: mineral_extraction_emission_df\n",
      "DataFrame Name: power_emission_df\n",
      "DataFrame Name: power_ownership_df\n",
      "DataFrame Name: waste_emission_df\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Create an empty dictionary to store DataFrames for each folder and file type\n",
    "folder_dfs = {}\n",
    "\n",
    "# Create separate dataframes for each folder and file type combination\n",
    "folders = all_files_df.select(\"folder\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "for folder in folders:\n",
    "    folder_df = all_files_df.filter(all_files_df.folder == folder)\n",
    "    \n",
    "    # Define DataFrame names dynamically based on folder name and file type\n",
    "    emission_df_name = f\"{folder}_emission_df\"\n",
    "    ownership_df_name = f\"{folder}_ownership_df\"\n",
    "    \n",
    "    # Separate emission and ownership files\n",
    "    emission_files = folder_df.filter(folder_df.file_type == \"emission_files\").collect()\n",
    "    ownership_files = folder_df.filter(folder_df.file_type == \"ownership_files\").collect()\n",
    "    \n",
    "    # Load data from CSV files into respective DataFrames\n",
    "    if emission_files:\n",
    "        emission_paths = [row.file_path for row in emission_files]\n",
    "        temp_emission_df = spark.read.option(\"header\", \"true\").csv(emission_paths)\n",
    "        # Add folder and file_type columns to temp_emission_df\n",
    "        temp_emission_df = temp_emission_df.withColumn(\"folder\", lit(folder)).withColumn(\"file_type\", lit(\"emission_files\"))\n",
    "        \n",
    "        # Store the DataFrame in the dictionary with the dynamic name\n",
    "        folder_dfs[emission_df_name] = temp_emission_df\n",
    "    \n",
    "    if ownership_files:\n",
    "        ownership_paths = [row.file_path for row in ownership_files]\n",
    "        temp_ownership_df = spark.read.option(\"header\", \"true\").csv(ownership_paths)\n",
    "        # Add folder and file_type columns to temp_ownership_df\n",
    "        temp_ownership_df = temp_ownership_df.withColumn(\"folder\", lit(folder)).withColumn(\"file_type\", lit(\"ownership_files\"))\n",
    "        \n",
    "        # Store the DataFrame in the dictionary with the dynamic name\n",
    "        folder_dfs[ownership_df_name] = temp_ownership_df\n",
    "\n",
    "# Display or perform operations on the separate DataFrames for each folder and file type\n",
    "for df_name, df in folder_dfs.items():\n",
    "    print(f\"DataFrame Name: {df_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sector wise Analysis - Agriculture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-------------------------+-------------------+-------------------+--------------------+----------+------------------+----------------+----------------------+--------+--------------+---------------+--------+--------------+-------------------+-------------+------------------+----------+--------------------+-----------+--------------+\n",
      "|  asset_id|iso3_country|original_inventory_sector|         start_time|           end_time|temporal_granularity|       gas|emissions_quantity|emissions_factor|emissions_factor_units|capacity|capacity_units|capacity_factor|activity|activity_units|       created_date|modified_date|        asset_name|asset_type|           st_astext|     folder|     file_type|\n",
      "+----------+------------+-------------------------+-------------------+-------------------+--------------------+----------+------------------+----------------+----------------------+--------+--------------+---------------+--------+--------------+-------------------+-------------+------------------+----------+--------------------+-----------+--------------+\n",
      "|1833727661|         TZA|           cropland-fires|2015-10-01 00:00:00|2015-10-31 00:00:00|               month|       co2|     38.4721239168|            1440|                  null|    2.26|          null|           2089|       2|          null|2022-10-31 00:00:00|         null|Tanzania_Morogoro_|  Cropland|POLYGON((37.625 -...|agriculture|emission_files|\n",
      "|1833727661|         TZA|           cropland-fires|2015-10-01 00:00:00|2015-10-31 00:00:00|               month|       ch4|     0.19633404672|             5.7|                  null|    2.26|          null|           2089|       2|          null|2022-10-31 00:00:00|         null|Tanzania_Morogoro_|  Cropland|POLYGON((37.625 -...|agriculture|emission_files|\n",
      "|1833727661|         TZA|           cropland-fires|2015-10-01 00:00:00|2015-10-31 00:00:00|               month|       n2o|     0.00233731008|             0.1|                  null|    2.26|          null|           2089|       2|          null|2022-10-31 00:00:00|         null|Tanzania_Morogoro_|  Cropland|POLYGON((37.625 -...|agriculture|emission_files|\n",
      "|1833727661|         TZA|           cropland-fires|2015-10-01 00:00:00|2015-10-31 00:00:00|               month|co2e_100yr|   44.587929472128|             0.1|                  null|    2.26|          null|           2089|       2|          null|2022-10-31 00:00:00|         null|Tanzania_Morogoro_|  Cropland|POLYGON((37.625 -...|agriculture|emission_files|\n",
      "|1833727661|         TZA|           cropland-fires|2015-10-01 00:00:00|2015-10-31 00:00:00|               month| co2e_20yr|   55.052534162304|             0.1|                  null|    2.26|          null|           2089|       2|          null|2022-10-31 00:00:00|         null|Tanzania_Morogoro_|  Cropland|POLYGON((37.625 -...|agriculture|emission_files|\n",
      "+----------+------------+-------------------------+-------------------+-------------------+--------------------+----------+------------------+----------------+----------------------+--------+--------------+---------------+--------+--------------+-------------------+-------------+------------------+----------+--------------------+-----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folder_dfs['agriculture_emission_df'].show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Initial cleaning - droping the unwanted columns, removing and filling the null values with the averages.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['start_time', 'end_time', 'temporal_granularity','created_date','modified_date']\n",
    "\n",
    "folder_dfs['agriculture_emission_df'] = folder_dfs['agriculture_emission_df'].drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, count,col\n",
    "\n",
    "null_counts = folder_dfs['agriculture_emission_df'] .agg(*[\n",
    "    count(when(col(c).isNull(), c)).alias(c)\n",
    "    for c in folder_dfs['agriculture_emission_df'] .columns\n",
    "])\n",
    "\n",
    "#null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import  avg\n",
    "columns_to_check = ['emissions_quantity','emissions_factor','capacity','capacity_factor','activity']\n",
    "# Calculate averages for specified columns\n",
    "avg_values = folder_dfs['agriculture_emission_df'].agg(*(avg(col(c)).alias(c) for c in columns_to_check))\n",
    "\n",
    "# Extract the averages\n",
    "avg_dict = avg_values.collect()[0].asDict()\n",
    "\n",
    "# Fill null values with averages\n",
    "agriculture_emission_df_new= folder_dfs['agriculture_emission_df'].fillna(avg_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asset_id: string (nullable = true)\n",
      " |-- iso3_country: string (nullable = true)\n",
      " |-- original_inventory_sector: string (nullable = true)\n",
      " |-- gas: string (nullable = true)\n",
      " |-- emissions_quantity: string (nullable = false)\n",
      " |-- emissions_factor: string (nullable = false)\n",
      " |-- emissions_factor_units: string (nullable = true)\n",
      " |-- capacity: string (nullable = false)\n",
      " |-- capacity_units: string (nullable = true)\n",
      " |-- capacity_factor: string (nullable = false)\n",
      " |-- activity: string (nullable = false)\n",
      " |-- activity_units: string (nullable = true)\n",
      " |-- asset_name: string (nullable = true)\n",
      " |-- asset_type: string (nullable = true)\n",
      " |-- st_astext: string (nullable = true)\n",
      " |-- folder: string (nullable = false)\n",
      " |-- file_type: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agriculture_emission_df_new.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the null count after cleaning\n",
    "\n",
    "null_counts_ = agriculture_emission_df_new .agg(*[\n",
    "    count(when(col(c).isNull(), c)).alias(c)\n",
    "    for c in agriculture_emission_df_new .columns\n",
    "])\n",
    "\n",
    "#null_counts_.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new metrics \n",
    "\n",
    "agriculture_emission_df_new= agriculture_emission_df_new.withColumn('Total Emissions', col('emissions_factor') * col('activity'))\n",
    "agriculture_emission_df_new= agriculture_emission_df_new.withColumn('Utilization', col('activity') * col('capacity'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agriculture_emission_df_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+--------------------+--------------------+-----------------------+-------------------+--------------------+-------------+-----------------------+--------------------+--------------------+-------------------+--------------------+-------------------------+-----------+---------------+\n",
      "|asset_id|     asset_name|          owner_name|owner_classification|percentage_of_ownership|owner_direct_parent|      owner_grouping|operator_name|percentage_of_operation|         data_source|                 url|            recency|        created_date|original_inventory_sector|     folder|      file_type|\n",
      "+--------+---------------+--------------------+--------------------+-----------------------+-------------------+--------------------+-------------+-----------------------+--------------------+--------------------+-------------------+--------------------+-------------------------+-----------+---------------+\n",
      "| 5099205|USA_CA_beef_275|Harris Feeding Co...|                null|                   null|               null|Harris Feeding Co...|         null|                   null|{'asset_name': ''...|{'asset_name': ''...|2021-12-31 00:00:00|2022-10-12 14:56:...|     enteric-fermentation|agriculture|ownership_files|\n",
      "| 5099206|USA_CA_beef_276|       Brandt Cattle|                null|                   null|               null|       Brandt Cattle|         null|                   null|{'asset_name': ''...|{'asset_name': ''...|2021-12-31 00:00:00|2022-10-12 14:56:...|     enteric-fermentation|agriculture|ownership_files|\n",
      "| 5099687|USA_TX_beef_459| Barrett and Crofoot|                null|                   null|               null| Barrett and Crofoot|         null|                   null|{'asset_name': ''...|{'asset_name': ''...|2021-12-31 00:00:00|2022-10-12 14:56:...|     enteric-fermentation|agriculture|ownership_files|\n",
      "| 5099689|USA_TX_beef_460|Five Rivers Cattl...|                null|                   null|               null|Five Rivers Cattl...|         null|                   null|{'asset_name': ''...|{'asset_name': ''...|2021-12-31 00:00:00|2022-10-12 14:56:...|     enteric-fermentation|agriculture|ownership_files|\n",
      "| 5099690|USA_TX_beef_461|      Cactus Feeders|                null|                   null|               null|      Cactus Feeders|         null|                   null|{'asset_name': ''...|{'asset_name': ''...|2021-12-31 00:00:00|2022-10-12 14:56:...|     enteric-fermentation|agriculture|ownership_files|\n",
      "+--------+---------------+--------------------+--------------------+-----------------------+-------------------+--------------------+-------------+-----------------------+--------------------+--------------------+-------------------+--------------------+-------------------------+-----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folder_dfs['agriculture_ownership_df'].show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Performing Left join between agriculture emission and ownership files, hence obtaining the owner_names for respective assets</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "agriculture_df_final = agriculture_emission_df_new.join(folder_dfs['agriculture_ownership_df'], ['asset_id', 'asset_name','original_inventory_sector','folder'], 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agriculture_df_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|original_inventory_sector|\n",
      "+-------------------------+\n",
      "|           cropland-fires|\n",
      "|     synthetic-fertili...|\n",
      "|        manure-management|\n",
      "|     enteric-fermentation|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agriculture_df_final.select(\"original_inventory_sector\").distinct().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agriculture - Synthetic fertilizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data based on original_inventory_sector\n",
    "filtered_df1 =  agriculture_df_final.filter(col('original_inventory_sector') == 'synthetic-fertilizer-application-top500')\n",
    "\n",
    "#filtered_df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|          asset_name|\n",
      "+--------------------+\n",
      "|China_Liaoning_Hu...|\n",
      "|China_Jiangsu_Nan...|\n",
      "|Spain_Castilla-La...|\n",
      "|Spain_Castilla-La...|\n",
      "|China_Shandong_Ji...|\n",
      "|India_West Bengal...|\n",
      "|Canada_Manitoba_D...|\n",
      "|India_Uttar Prade...|\n",
      "|China_Liaoning_Pa...|\n",
      "|India_Uttar Prade...|\n",
      "|United States_Cal...|\n",
      "|Indonesia_Kaliman...|\n",
      "|India_Uttar Prade...|\n",
      "|China_Hunan_Hengyang|\n",
      "|China_Jiangsu_Lia...|\n",
      "|China_Shandong_Li...|\n",
      "|China_Jilin_Liaoyuan|\n",
      "|India_Uttar Prade...|\n",
      "|China_Fujian_Nanping|\n",
      "| China_Jilin_Tonghua|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df1.select(\"asset_name\").distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+\n",
      "|   Asset_Group|   count|\n",
      "+--------------+--------+\n",
      "|         China|19234810|\n",
      "|         India| 8295805|\n",
      "|        Canada| 3113390|\n",
      "|      Pakistan| 1909950|\n",
      "|         Spain|  763865|\n",
      "|United Kingdom|  479780|\n",
      "|        France|  428085|\n",
      "|     Indonesia|  303835|\n",
      "| United States|  183400|\n",
      "|  South Africa|  127750|\n",
      "|    Bangladesh|  116830|\n",
      "|         Egypt|   14175|\n",
      "+--------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, split\n",
    "\n",
    "# Split the 'asset_name' column by underscore and get the first part i.e., country name\n",
    "grouped_df = filtered_df1.withColumn(\"Asset_Group\", split(col(\"asset_name\"), \"_\").getItem(0))\n",
    "\n",
    "# Group by the 'Group' column and count occurrences\n",
    "grouped_result = grouped_df.groupBy(\"Asset_Group\").count().orderBy(\"count\", ascending=False)\n",
    "\n",
    "grouped_result.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouped_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+----------+-------------------------+--------------------+--------------------+--------------------+------------------+---------------+------------------+------------------+------------------+\n",
      "|Asset_Group|  asset_type|       gas|original_inventory_sector|          asset_name|  emissions_quantity|    emissions_factor|          capacity|capacity_factor|          activity|   Total Emissions|       Utilization|\n",
      "+-----------+------------+----------+-------------------------+--------------------+--------------------+--------------------+------------------+---------------+------------------+------------------+------------------+\n",
      "|     France|  Vegetables|       n2o|     synthetic-fertili...|France_Grand Est_...|0.006638373513446747|0.015714285714285695|  8.14886603282457|         2089.0| 50.20292144499993|0.7889030512785705|411.75182069456383|\n",
      "|      India|       Maize|co2e_100yr|     synthetic-fertili...|India_Madhya Prad...|  10.450277673450199| 0.01571428571428571| 37.23610922072498|         2089.0|62.638609211219986|0.9843210018905979|2350.9643086524875|\n",
      "|      China|  Vegetables|co2e_100yr|     synthetic-fertili...|China_Guizhou_Qia...|   44.76691708844288| 0.01571428571428568| 157.9651911053929|         2089.0| 64.14450263263649|1.0079850413700016|10267.707642781328|\n",
      "|      China|    CropsNES|       ch4|     synthetic-fertili...|China_Beijing_Bei...|   242.8401100063354|  100.99332856877776|103.21523364007955|         2089.0|23.503814179408685|2373.7284280405192|2450.2078624255305|\n",
      "|     Canada|Othercereals|       ch4|     synthetic-fertili...|Canada_Alberta_Di...|  242.84011000633535|    100.993328568778| 6.268932626300573|         2089.0|  69.5123938433737| 7020.288031026123| 436.8126744924554|\n",
      "+-----------+------------+----------+-------------------------+--------------------+--------------------+--------------------+------------------+---------------+------------------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group by 'Asset_Group' and 'asset_type', calculate average of all values\n",
    "grouped_avg = grouped_df.groupBy(\"Asset_Group\", \"asset_type\" , \"gas\",\"original_inventory_sector\",\"asset_name\").agg(\n",
    "        avg(col(\"emissions_quantity\")).alias(\"emissions_quantity\"),\n",
    "       avg(col(\"emissions_factor\")).alias(\"emissions_factor\"),\n",
    "        avg(col(\"capacity\")).alias(\"capacity\"),\n",
    "        avg(col(\"capacity_factor\")).alias(\"capacity_factor\"),\n",
    "        avg(col(\"activity\")).alias(\"activity\"),\n",
    "        avg(col(\"Total Emissions\")).alias(\"Total Emissions\"),\n",
    "        avg(col(\"Utilization\")).alias(\"Utilization\")\n",
    "    \n",
    ")\n",
    "\n",
    "grouped_avg.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agriculture - Enteric-fermentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data based on original_inventory_sector (example: filtering for 'sector_name')\n",
    "filtered_df2 =  agriculture_df_final.filter(col('original_inventory_sector') == 'enteric-fermentation')\n",
    "\n",
    "#filtered_df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+-----+\n",
      "|Asset_Group|asset_category|count|\n",
      "+-----------+--------------+-----+\n",
      "|        USA|         dairy| 7480|\n",
      "|        USA|          beef| 7095|\n",
      "|        ARG|          beef|  690|\n",
      "|        ARG|         dairy|   40|\n",
      "+-----------+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, col, split\n",
    "\n",
    "# Split the 'asset_name' column by underscore and get the first part\n",
    "grouped_df2 = filtered_df2.withColumn(\"Asset_Group\", split(col(\"asset_type\"), \"_\").getItem(0))\n",
    "\n",
    "# Create a new column 'asset_category' based on the below conditions in 'asset_name'\n",
    "grouped_df2 = grouped_df2.withColumn(\n",
    "    \"asset_category\",\n",
    "    when(col(\"asset_type\").contains(\"beef\"), \"beef\")\n",
    "    .when(col(\"asset_type\").contains(\"dairy\"), \"dairy\")\n",
    "    .otherwise(\"asset_type\")\n",
    ")\n",
    "\n",
    "# Group by the 'Asset_Group' and 'asset_category' columns and count occurrences\n",
    "grouped_result2 = grouped_df2.groupBy(\"Asset_Group\", \"asset_category\").count().orderBy(\"count\", ascending=False)\n",
    "\n",
    "grouped_result2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Asset_Group' and 'asset_type', calculate average of all values\n",
    "grouped_avg2 = grouped_df2.groupBy(\"Asset_Group\",\"asset_category\",\"asset_type\" , \"gas\",\"asset_name\",\"original_inventory_sector\").agg(\n",
    "        avg(col(\"emissions_quantity\")).alias(\"emissions_quantity\"),\n",
    "       avg(col(\"emissions_factor\")).alias(\"emissions_factor\"),\n",
    "        avg(col(\"capacity\")).alias(\"capacity\"),\n",
    "        avg(col(\"capacity_factor\")).alias(\"capacity_factor\"),\n",
    "        avg(col(\"activity\")).alias(\"activity\"),\n",
    "        avg(col(\"Total Emissions\")).alias(\"Total Emissions\"),\n",
    "        avg(col(\"Utilization\")).alias(\"Utilization\")\n",
    "    \n",
    ")\n",
    "\n",
    "#grouped_avg2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "# Provided asset names and owner names\n",
    "asset_owner_data = [\n",
    "    (\"USA_CA_beef_275\", \"Harris Feeding Company\"),\n",
    "    (\"USA_CA_beef_276\", \"Brandt Cattle\"),\n",
    "    (\"USA_TX_beef_459\", \"Barrett and Crofoot\"),\n",
    "    (\"USA_TX_beef_460\", \"Five Rivers Cattle Feeding\"),\n",
    "    (\"USA_TX_beef_461\", \"Cactus Feeders\"),\n",
    "    (\"USA_TX_beef_464\", \"Champion Feeders\"),\n",
    "    (\"USA_TX_beef_465\", \"Bar-G Feedyard\"),\n",
    "    (\"USA_TX_beef_467\", \"Friona Industries\")\n",
    "]\n",
    "\n",
    "# Create a dictionary using comprehension\n",
    "asset_owner_dict = {asset_type: owner_name for asset_type, owner_name in asset_owner_data}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "dict_df = spark.createDataFrame(list(asset_owner_dict.items()), [\"asset_type\", \"owner_name\"])\n",
    "# Join 'grouped_avg2' with the DataFrame created from the dictionary\n",
    "updated_df = grouped_avg2.join(\n",
    "    dict_df,\n",
    "    on=[\"asset_type\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------+--------------+----+----------+-------------------------+------------------+------------------+--------+---------------+-----------------+------------------+-----------+----------+\n",
      "|      asset_type|Asset_Group|asset_category| gas|asset_name|original_inventory_sector|emissions_quantity|  emissions_factor|capacity|capacity_factor|         activity|   Total Emissions|Utilization|owner_name|\n",
      "+----------------+-----------+--------------+----+----------+-------------------------+------------------+------------------+--------+---------------+-----------------+------------------+-----------+----------+\n",
      "|     ARG_beef_12|        ARG|          beef|null|      null|     enteric-fermentation|              null|         1698.1328|    null|           null|72.89330596466804|123782.51375903845|       null|      null|\n",
      "|USA_CA_dairy_410|        USA|         dairy|null|      null|     enteric-fermentation|              null|           1883.52|    null|           null|72.89330596466804|137295.99965057155|       null|      null|\n",
      "|USA_CA_dairy_492|        USA|         dairy|null|      null|     enteric-fermentation|              null|          2218.368|    null|           null|72.89330596466804|161704.17736622872|       null|      null|\n",
      "|USA_CA_dairy_614|        USA|         dairy|null|      null|     enteric-fermentation|              null|2734.5919999999996|    null|           null|72.89330596466804|199333.45134453353|       null|      null|\n",
      "|USA_CA_dairy_792|        USA|         dairy|null|      null|     enteric-fermentation|              null|3627.5199999999995|    null|           null|72.89330596466804| 264421.9252529526|       null|      null|\n",
      "+----------------+-----------+--------------+----+----------+-------------------------+------------------+------------------+--------+---------------+-----------------+------------------+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "updated_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agriculture - Manure Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data based on original_inventory_sector (example: filtering for 'sector_name')\n",
    "filtered_df3 =  agriculture_df_final.filter(col('original_inventory_sector') == 'manure-management')\n",
    "\n",
    "#filtered_df3.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+-----+\n",
      "|Asset_Group|asset_category|count|\n",
      "+-----------+--------------+-----+\n",
      "|        USA|         dairy| 7480|\n",
      "|        USA|          beef| 7035|\n",
      "|        ARG|          beef|  690|\n",
      "|        ARG|         dairy|   40|\n",
      "+-----------+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, col, split\n",
    "\n",
    "# Split the 'asset_name' column by underscore and get the first part\n",
    "grouped_df3 = filtered_df3.withColumn(\"Asset_Group\", split(col(\"asset_type\"), \"_\").getItem(0))\n",
    "\n",
    "# Create a new column 'asset_category' based on conditions in 'asset_name'\n",
    "grouped_df3 = grouped_df3.withColumn(\n",
    "    \"asset_category\",\n",
    "    when(col(\"asset_type\").contains(\"beef\"), \"beef\")\n",
    "    .when(col(\"asset_type\").contains(\"dairy\"), \"dairy\")\n",
    "    .otherwise(\"asset_type\")\n",
    ")\n",
    "\n",
    "# Group by the 'Asset_Group' and 'asset_category' columns and count occurrences\n",
    "grouped_result3 = grouped_df3.groupBy(\"Asset_Group\", \"asset_category\").count().orderBy(\"count\", ascending=False)\n",
    "\n",
    "grouped_result3.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Asset_Group' and 'asset_type', calculate average of all values\n",
    "grouped_avg3 = grouped_df3.groupBy(\"Asset_Group\",\"asset_category\",\"asset_type\" , \"gas\",\"asset_name\",\"owner_name\",\"original_inventory_sector\").agg(\n",
    "        avg(col(\"emissions_quantity\")).alias(\"emissions_quantity\"),\n",
    "       avg(col(\"emissions_factor\")).alias(\"emissions_factor\"),\n",
    "        avg(col(\"capacity\")).alias(\"capacity\"),\n",
    "        avg(col(\"capacity_factor\")).alias(\"capacity_factor\"),\n",
    "        avg(col(\"activity\")).alias(\"activity\"),\n",
    "        avg(col(\"Total Emissions\")).alias(\"Total Emissions\"),\n",
    "        avg(col(\"Utilization\")).alias(\"Utilization\")\n",
    "    \n",
    ")\n",
    "\n",
    "#grouped_avg3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "agriculture_df_3 =  updated_df.union(grouped_avg3)\n",
    "#agriculture_df_3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "agriculture_df_1 = grouped_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agriculture - Cropland-fires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data based on original_inventory_sector (example: filtering for 'sector_name')\n",
    "filtered_df =  agriculture_df_final.filter(col('original_inventory_sector') == 'cropland-fires')\n",
    "#filtered_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the 'Group' column and count occurrences\n",
    "grouped_result5 = filtered_df.groupBy(\"asset_name\").count().orderBy(\"count\", ascending=False)\n",
    "#grouped_result5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the 'asset_name' column by underscore and get the first part\n",
    "grouped_df4 = filtered_df.withColumn(\"Asset_Group\", split(col(\"asset_name\"), \"_\").getItem(0))\n",
    "# Split the 'asset_name' column by underscore and get the first part\n",
    "grouped_df4 = grouped_df4.withColumn(\"Asset_SubGroup\", split(col(\"asset_name\"), \"_\").getItem(1))\n",
    "\n",
    "#grouped_df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-----+\n",
      "|Asset_Group| Asset_SubGroup|count|\n",
      "+-----------+---------------+-----+\n",
      "|      India|    Maharashtra|95280|\n",
      "|      India|  Uttar Pradesh|88515|\n",
      "|      China|   Heilongjiang|84360|\n",
      "|      India| Madhya Pradesh|76980|\n",
      "|   Pakistan|         Punjab|73910|\n",
      "|      China|     Nei Mongol|69640|\n",
      "|     Brazil|   Minas Gerais|61605|\n",
      "|      China|          Hebei|60995|\n",
      "|     Brazil|      São Paulo|58135|\n",
      "|     Brazil|          Goiás|54900|\n",
      "|     Brazil|    Mato Grosso|54055|\n",
      "|      China|         Yunnan|52490|\n",
      "|      China|       Shandong|51865|\n",
      "|      India|      Karnataka|51600|\n",
      "|      India| Andhra Pradesh|49485|\n",
      "|  Australia|New South Wales|46760|\n",
      "|      China|       Liaoning|46530|\n",
      "|      India|      Telangana|46465|\n",
      "|      China|          Jilin|45465|\n",
      "|     Brazil|         Paraná|44580|\n",
      "+-----------+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Group by the 'Group' column and count occurrences\n",
    "grouped_result6 = grouped_df4.groupBy(\"Asset_Group\",\"Asset_SubGroup\").count().orderBy(\"count\", ascending=False)\n",
    "\n",
    "grouped_result6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+----------+----------+-------------------------+--------------------+-------------------+------------------+---------------+------------------+-------------------+------------------+\n",
      "|  Asset_Group|      Asset_SubGroup|asset_type|       gas|original_inventory_sector|  emissions_quantity|   emissions_factor|          capacity|capacity_factor|          activity|    Total Emissions|       Utilization|\n",
      "+-------------+--------------------+----------+----------+-------------------------+--------------------+-------------------+------------------+---------------+------------------+-------------------+------------------+\n",
      "|     Thailand|            Yasothon|  Cropland|       n2o|           cropland-fires| 0.06560131349387752|0.09999999999999991|63.431450437317785|         2089.0| 10.26773566569485| 1.0267735665694848| 1540.835151745222|\n",
      "|     Ethiopia|    Benshangul-Gumaz|  Cropland|       n2o|           cropland-fires| 0.08639054476776177|0.09999999999999984|  83.5330463192721|         2089.0| 8.733912324234904| 0.8733912324234905|2857.0794982078855|\n",
      "|       Latvia|             Zemgale|  Cropland|       co2|           cropland-fires|   85.34830355121356|             1440.0| 5.013686440677966|         2089.0|0.7902542372881356| 1137.9661016949153|10.044233757062148|\n",
      "|United States|             Indiana|  Cropland|       co2|           cropland-fires|  111.32972154748293|             1440.0| 6.539934505342985|         2089.0| 1.779041709755257|   2561.82006204757|21.733658700065117|\n",
      "|    Argentina|             Mendoza|  Cropland|co2e_100yr|           cropland-fires|   351.8920237995243|0.09999999999999987|17.836127023661266|         2089.0|2.3250311332503113|0.23250311332503112| 82.30910647571608|\n",
      "|      Uruguay|             Artigas|  Cropland| co2e_20yr|           cropland-fires|  190.37417815890095|                0.1| 7.815183246073299|         2089.0|1.2783595113438044|0.12783595113438045|19.548962696335074|\n",
      "|United States|            Colorado|  Cropland|       n2o|           cropland-fires|0.025051651723636346|0.09999999999999992|24.223030303030306|         2089.0| 2.379157427937916|0.23791574279379152| 261.4253236634639|\n",
      "|      Ukraine|              Odessa|  Cropland|co2e_100yr|           cropland-fires|  1550.9068071368335|0.10000000000000003|  78.6098261485826|         2089.0|  9.79332355816227| 0.9793323558162268| 5566.534827989573|\n",
      "|      Nigeria|             Adamawa|  Cropland| co2e_20yr|           cropland-fires|    1044.01234893312|0.09999999999999996| 42.85847953216375|         2089.0| 7.131886734379808|  0.713188673437981|1469.8922064481376|\n",
      "|       France|Bourgogne-Franche...|  Cropland| co2e_20yr|           cropland-fires|  197.09862142740877|0.10000000000000003| 8.091233059548255|         2089.0|1.2714579055441477|0.12714579055441477| 25.74616872575862|\n",
      "+-------------+--------------------+----------+----------+-------------------------+--------------------+-------------------+------------------+---------------+------------------+-------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group by 'Asset_Group' and 'asset_type', calculate average of all values\n",
    "grouped_avg4 = grouped_df4.groupBy(\"Asset_Group\",\"Asset_SubGroup\",\"asset_type\",\"gas\",\"original_inventory_sector\").agg(\n",
    "        avg(col(\"emissions_quantity\")).alias(\"emissions_quantity\"),\n",
    "       avg(col(\"emissions_factor\")).alias(\"emissions_factor\"),\n",
    "        avg(col(\"capacity\")).alias(\"capacity\"),\n",
    "        avg(col(\"capacity_factor\")).alias(\"capacity_factor\"),\n",
    "        avg(col(\"activity\")).alias(\"activity\"),\n",
    "        avg(col(\"Total Emissions\")).alias(\"Total Emissions\"),\n",
    "        avg(col(\"Utilization\")).alias(\"Utilization\")\n",
    "    \n",
    ")\n",
    "\n",
    "grouped_avg4.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "agriculture_df_2 =grouped_avg4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sector 2:  Power - Electricity Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+-------------------------+-------------------+-------------------+--------------------+----------+------------------+----------------+----------------------+--------+-------------------+---------------+--------+--------------+--------------------+--------------------+--------------------+----------+--------------------+------+--------------+\n",
      "|asset_id|iso3_country|original_inventory_sector|         start_time|           end_time|temporal_granularity|       gas|emissions_quantity|emissions_factor|emissions_factor_units|capacity|     capacity_units|capacity_factor|activity|activity_units|        created_date|       modified_date|          asset_name|asset_type|           st_astext|folder|     file_type|\n",
      "+--------+------------+-------------------------+-------------------+-------------------+--------------------+----------+------------------+----------------+----------------------+--------+-------------------+---------------+--------+--------------+--------------------+--------------------+--------------------+----------+--------------------+------+--------------+\n",
      "| 1670098|         DEU|     electricity-gener...|2019-01-01 00:00:00|2019-12-31 00:00:00|              annual|       ch4|              null|            null|    tonnes_gas_per_MWh|    1510|PP_max_capacity(MW)|           0.71| 9345000|generation_MWh|2022-09-01 16:53:...|2023-03-06 18:24:...|Schwarze Pumpe po...|      coal|POINT(14.3535 51....| power|emission_files|\n",
      "| 1670320|         USA|     electricity-gener...|2020-01-01 00:00:00|2020-12-31 00:00:00|              annual|       co2|           6853000|           0.934|    tonnes_gas_per_MWh|    1717|PP_max_capacity(MW)|          0.487| 7339000|generation_MWh|2022-09-01 16:53:...|                null|     Mill Creek (KY)|      coal|POINT(-85.9103 38...| power|emission_files|\n",
      "| 1670320|         USA|     electricity-gener...|2020-01-01 00:00:00|2020-12-31 00:00:00|              annual|       ch4|              null|            null|    tonnes_gas_per_MWh|    1717|PP_max_capacity(MW)|          0.487| 7339000|generation_MWh|2022-09-01 16:53:...|                null|     Mill Creek (KY)|      coal|POINT(-85.9103 38...| power|emission_files|\n",
      "| 1670320|         USA|     electricity-gener...|2020-01-01 00:00:00|2020-12-31 00:00:00|              annual|       n2o|              null|            null|    tonnes_gas_per_MWh|    1717|PP_max_capacity(MW)|          0.487| 7339000|generation_MWh|2022-09-01 16:53:...|                null|     Mill Creek (KY)|      coal|POINT(-85.9103 38...| power|emission_files|\n",
      "| 1670320|         USA|     electricity-gener...|2020-01-01 00:00:00|2020-12-31 00:00:00|              annual|co2e_100yr|           6853000|            null|    tonnes_gas_per_MWh|    1717|PP_max_capacity(MW)|          0.487| 7339000|generation_MWh|2022-09-01 16:53:...|                null|     Mill Creek (KY)|      coal|POINT(-85.9103 38...| power|emission_files|\n",
      "+--------+------------+-------------------------+-------------------+-------------------+--------------------+----------+------------------+----------------+----------------------+--------+-------------------+---------------+--------+--------------+--------------------+--------------------+--------------------+----------+--------------------+------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folder_dfs['power_emission_df'].show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asset_id: string (nullable = true)\n",
      " |-- iso3_country: string (nullable = true)\n",
      " |-- original_inventory_sector: string (nullable = true)\n",
      " |-- start_time: string (nullable = true)\n",
      " |-- end_time: string (nullable = true)\n",
      " |-- temporal_granularity: string (nullable = true)\n",
      " |-- gas: string (nullable = true)\n",
      " |-- emissions_quantity: string (nullable = true)\n",
      " |-- emissions_factor: string (nullable = true)\n",
      " |-- emissions_factor_units: string (nullable = true)\n",
      " |-- capacity: string (nullable = true)\n",
      " |-- capacity_units: string (nullable = true)\n",
      " |-- capacity_factor: string (nullable = true)\n",
      " |-- activity: string (nullable = true)\n",
      " |-- activity_units: string (nullable = true)\n",
      " |-- created_date: string (nullable = true)\n",
      " |-- modified_date: string (nullable = true)\n",
      " |-- asset_name: string (nullable = true)\n",
      " |-- asset_type: string (nullable = true)\n",
      " |-- st_astext: string (nullable = true)\n",
      " |-- folder: string (nullable = false)\n",
      " |-- file_type: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folder_dfs['power_emission_df'].printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['start_time', 'end_time', 'temporal_granularity','created_date','modified_date']\n",
    "\n",
    "folder_dfs['power_emission_df'] = folder_dfs['power_emission_df'].drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, count,col\n",
    "\n",
    "null_counts = folder_dfs['power_emission_df'] .agg(*[\n",
    "    count(when(col(c).isNull(), c)).alias(c)\n",
    "    for c in folder_dfs['power_emission_df'] .columns\n",
    "])\n",
    "\n",
    "#null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_emission_df_new = folder_dfs['power_emission_df'].dropna(subset=['emissions_quantity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_emission_df_new= power_emission_df_new.withColumn('Total Emissions', col('emissions_factor') * col('activity'))\n",
    "power_emission_df_new= power_emission_df_new.withColumn('Utilization', col('activity') * col('capacity'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    " power_df_final = power_emission_df_new.join(folder_dfs['power_ownership_df'], ['asset_id', 'asset_name','original_inventory_sector','folder'], 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-------------------------+------+------------+----------+------------------+----------------+----------------------+--------+-------------------+---------------+--------+--------------+----------+--------------------+---------------+------------+--------------------+--------------+\n",
      "|asset_id|          asset_name|original_inventory_sector|folder|iso3_country|       gas|emissions_quantity|emissions_factor|emissions_factor_units|capacity|     capacity_units|capacity_factor|activity|activity_units|asset_type|           st_astext|Total Emissions| Utilization|          owner_name|owner_grouping|\n",
      "+--------+--------------------+-------------------------+------+------------+----------+------------------+----------------+----------------------+--------+-------------------+---------------+--------+--------------+----------+--------------------+---------------+------------+--------------------+--------------+\n",
      "| 1670320|     Mill Creek (KY)|     electricity-gener...| power|         USA|       co2|           6853000|           0.934|    tonnes_gas_per_MWh|    1717|PP_max_capacity(MW)|          0.487| 7339000|generation_MWh|      coal|POINT(-85.9103 38...|      6854626.0|1.2601063E10|Louisville Gas & ...|    PPL Energy|\n",
      "| 1670320|     Mill Creek (KY)|     electricity-gener...| power|         USA|co2e_100yr|           6853000|            null|    tonnes_gas_per_MWh|    1717|PP_max_capacity(MW)|          0.487| 7339000|generation_MWh|      coal|POINT(-85.9103 38...|           null|1.2601063E10|Louisville Gas & ...|    PPL Energy|\n",
      "| 1670098|Schwarze Pumpe po...|     electricity-gener...| power|         DEU|       co2|          11744000|           1.127|    tonnes_gas_per_MWh|    1510|PP_max_capacity(MW)|           0.79|10435000|generation_MWh|      coal|POINT(14.3535 51....|    1.1760245E7| 1.575685E10|                LEAG|           EPH|\n",
      "| 1670001|Boxberg power sta...|     electricity-gener...| power|         DEU|       co2|          15011000|           1.099|    tonnes_gas_per_MWh|    2470|PP_max_capacity(MW)|           0.64|13789000|generation_MWh|      coal|POINT(14.5684 51....|    1.5154111E7| 3.405883E10|                LEAG|           EPH|\n",
      "| 1670111|Janschwalde power...|     electricity-gener...| power|         DEU|       co2|          18000000|           1.186|    tonnes_gas_per_MWh|    2375|PP_max_capacity(MW)|           0.73|15101000|generation_MWh|      coal|POINT(14.4578 51....|    1.7909786E7|3.5864875E10|                LEAG|           EPH|\n",
      "+--------+--------------------+-------------------------+------+------------+----------+------------------+----------------+----------------------+--------+-------------------+---------------+--------+--------------+----------+--------------------+---------------+------------+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select specific columns using col() function\n",
    "power_df_output = power_df_final.select(\n",
    "    col(\"asset_id\"),\n",
    "    col(\"asset_name\"),\n",
    "    col(\"original_inventory_sector\"),\n",
    "    col(\"folder\"),\n",
    "    col(\"iso3_country\"),\n",
    "    col(\"gas\"),\n",
    "    col(\"emissions_quantity\"),\n",
    "    col(\"emissions_factor\"),\n",
    "    col(\"emissions_factor_units\"),\n",
    "    col(\"capacity\"),\n",
    "    col(\"capacity_units\"),\n",
    "    col(\"capacity_factor\"),\n",
    "    col(\"activity\"),\n",
    "    col(\"activity_units\"),\n",
    "    col(\"asset_type\"),\n",
    "    col(\"st_astext\"),\n",
    "    col(\"Total Emissions\"),\n",
    "    col(\"Utilization\"),\n",
    "    col(\"owner_name\"), \n",
    "    col(\"owner_grouping\")\n",
    ")\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "power_df_output.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|          asset_type|count|\n",
      "+--------------------+-----+\n",
      "|                coal| 5286|\n",
      "|   gas, other_fossil|  238|\n",
      "|           coal, gas|  232|\n",
      "|           coal, oil|  205|\n",
      "|coal, gas, other_...|  145|\n",
      "|                 gas|  122|\n",
      "|          gas_or_oil|   67|\n",
      "|   oil, other_fossil|   66|\n",
      "|           gas, coal|   58|\n",
      "|  coal, other_fossil|   49|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group by the 'Group' column and count occurrences\n",
    "Power_group = power_df_output.groupBy(\"asset_type\").count().orderBy(\"count\", ascending=False)\n",
    "Power_group.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lower, split, explode, col\n",
    "\n",
    "# Create a temporary table with the simplified asset types\n",
    "power_df_output.select(\n",
    "    explode(split(col(\"asset_type\"), \", \")).alias(\"Asset_Category\")\n",
    ").createOrReplaceTempView(\"Asset_categories\")\n",
    "\n",
    "# Read the temporary table into a DataFrame\n",
    "Asset_categories_counts = spark.sql(\n",
    "    \"SELECT Asset_Category, count(*) AS count FROM Asset_categories GROUP BY Asset_Category ORDER BY count DESC\"\n",
    ")\n",
    "\n",
    "# Sort the DataFrame by count in descending order\n",
    "Asset_categories_count = Asset_categories_counts.orderBy(\"count\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|Asset_Category|count|\n",
      "+--------------+-----+\n",
      "|          coal| 6081|\n",
      "|           gas| 1059|\n",
      "|  other_fossil|  711|\n",
      "|           oil|  492|\n",
      "|    gas_or_oil|  250|\n",
      "|       biomass|   27|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Asset_categories_count.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_df_group = power_df_output.withColumn(\"Asset_category\", explode(split(col(\"asset_type\"), \", \")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----------+-------------------------+--------------------+--------------------+------------+--------------------+------------------+--------+-------------------+--------------------+-----------------+--------------------+\n",
      "|Asset_category|          asset_name|       gas|original_inventory_sector|          owner_name|      owner_grouping|iso3_country|  emissions_quantity|  emissions_factor|capacity|    capacity_factor|            activity|  Total Emissions|         Utilization|\n",
      "+--------------+--------------------+----------+-------------------------+--------------------+--------------------+------------+--------------------+------------------+--------+-------------------+--------------------+-----------------+--------------------+\n",
      "|           oil|  Safi power station|       co2|     electricity-gener...| Safi Energy Company|Sofina and Nareva...|         MAR|   6969333.333333333|             1.006|  1388.0| 0.5693333333333332|           6927000.0|        6968562.0|          9.614676E9|\n",
      "|          coal|Talcher Kaniha Su...| co2e_20yr|     electricity-gener...|            NTPC Ltd|        NTPC (India)|         IND|1.3516666666666666E7|              null|  3000.0| 0.5483333333333333|1.4422666666666666E7|             null|           4.3268E10|\n",
      "|          coal|Jeffrey Energy Ce...|co2e_100yr|     electricity-gener...|   Westar Energy Inc|              Evergy|         USA|           7701000.0|              null|  2160.0|0.43533333333333335|           8248000.0|             null|         1.781568E10|\n",
      "|          coal|Barh I power station|co2e_100yr|     electricity-gener...|            NTPC Ltd|        NTPC (India)|         IND|           6975000.0|              null|  1540.0| 0.5483333333333333|   7442333.333333333|             null|         1.199506E10|\n",
      "|          coal|Hebi Fenghe power...|       co2|     electricity-gener...|Hebi Fenghe Power...|Hebi Coal Industr...|         CHN|   6889666.666666667|0.8969999999999999|  1800.0|0.48666666666666664|   7677666.666666667|        6886867.0|          1.38198E10|\n",
      "|          coal|Huaneng Yimin pow...|co2e_100yr|     electricity-gener...|HUA NENG Yimin Co...|China Huaneng (Ch...|         CHN|            1.5812E7|              null|  3400.0| 0.5913333333333333|             1.762E7|             null|           5.9908E10|\n",
      "|          coal|Nazarovskaya powe...|       co2|     electricity-gener...|TGC-13 (OJSC Yeni...|                SUEK|         RUS|           6019000.0|             1.222|  1362.0| 0.4126666666666667|   4927333.333333333|6021201.333333333|          6.711028E9|\n",
      "|          coal|Huangtai power st...|co2e_100yr|     electricity-gener...|Huaneng Jinan Hua...|China Huaneng (Ch...|         CHN|   6256333.333333333|              null|  1360.0| 0.5846666666666667|   6971333.333333333|             null| 9.481013333333334E9|\n",
      "|          coal|Ligang power station|       co2|     electricity-gener...|Jiangsu Ligang El...|         CITIC Group|         CHN|            1.5496E7|0.8969999999999999|  3960.0|0.49700000000000005|1.7267666666666668E7|      1.5489097E7|         6.837996E10|\n",
      "|          coal|Guangdong Huilai ...|       co2|     electricity-gener...|Guangdong Yudean ...|Guangdong Yudean ...|         CHN|1.0411333333333334E7|0.8969999999999999|  3200.0| 0.4136666666666667|1.1601333333333334E7|      1.0406396E7|3.712426666666666...|\n",
      "+--------------+--------------------+----------+-------------------------+--------------------+--------------------+------------+--------------------+------------------+--------+-------------------+--------------------+-----------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group by 'Asset_Group' and 'asset_type', calculate average of all values\n",
    "grouped_avg_power = power_df_group.groupBy(\"Asset_category\",\"asset_name\", \"gas\",\"original_inventory_sector\",\"owner_name\",\"owner_grouping\",\"iso3_country\").agg(\n",
    "        avg(col(\"emissions_quantity\")).alias(\"emissions_quantity\"),\n",
    "       avg(col(\"emissions_factor\")).alias(\"emissions_factor\"),\n",
    "        avg(col(\"capacity\")).alias(\"capacity\"),\n",
    "        avg(col(\"capacity_factor\")).alias(\"capacity_factor\"),\n",
    "        avg(col(\"activity\")).alias(\"activity\"),\n",
    "        avg(col(\"Total Emissions\")).alias(\"Total Emissions\"),\n",
    "        avg(col(\"Utilization\")).alias(\"Utilization\")\n",
    "    \n",
    ")\n",
    "\n",
    "grouped_avg_power.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Sector 3:  Fossil Fuel operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder_dfs['fossil_fuel_operations_emission_df'].show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is issue in ingesting data for the above df all the fields are being null, so definining individual schema for fossil fuel files and merging them into single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hdfs://localhost:9000/user/username/project_data/Data/fossil_fuel_operations/asset_coal-mining_emissions.csv', 'hdfs://localhost:9000/user/username/project_data/Data/fossil_fuel_operations/asset_oil-and-gas-production-and-transport_emissions.csv', 'hdfs://localhost:9000/user/username/project_data/Data/fossil_fuel_operations/asset_oil-and-gas-refining_emissions.csv']\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "    \n",
    "    #Filter all_files_df based on conditions\n",
    "filtered_files_df = all_files_df.filter(\n",
    "    (all_files_df.folder == \"fossil_fuel_operations\") & \n",
    "    (all_files_df.file_type == \"emission_files\")\n",
    ")\n",
    "\n",
    "# Collect the file paths from the filtered DataFrame\n",
    "file_paths = filtered_files_df.select(\"file_path\").rdd.flatMap(lambda x: x).collect()\n",
    "print(file_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, DoubleType\n",
    "\n",
    "\n",
    "# Read CSV files into chunks using the collected file paths and specified schema\n",
    "dataframes = []\n",
    "for file_path in file_paths:\n",
    "    df_chunks = spark.read.format(\"csv\").option(\"header\", \"true\").load(file_path)\n",
    "    dataframes.append(df_chunks)\n",
    "\n",
    "# Show the merged DataFrame\n",
    "#merged_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fossil fuels - Coal Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+-------------------------+-------+----------+------------------+----------------+----------------------+--------+---------------+---------------+--------+--------------------+--------------------+----------+--------------------+\n",
      "| asset_id|iso3_country|original_inventory_sector|lat_lon|       gas|emissions_quantity|emissions_factor|emissions_factor_units|capacity| capacity_units|capacity_factor|activity|      activity_units|          asset_name|asset_type|           st_astext|\n",
      "+---------+------------+-------------------------+-------+----------+------------------+----------------+----------------------+--------+---------------+---------------+--------+--------------------+--------------------+----------+--------------------+\n",
      "|136113483|         CHN|              coal-mining|   null|       co2|                 0|               0|  tonnes_gas_per_co...|     1.5|coal_mine_depth|          0.752|   1.128|tonnes_coal_extra...|Tashan Coal Mine ...|Bituminous|POINT(113.047421 ...|\n",
      "|136113483|         CHN|              coal-mining|   null|       ch4|             20557|           18224|  tonnes_gas_per_co...|     1.5|coal_mine_depth|          0.752|   1.128|tonnes_coal_extra...|Tashan Coal Mine ...|Bituminous|POINT(113.047421 ...|\n",
      "|136113483|         CHN|              coal-mining|   null|       n2o|                 0|               0|  tonnes_gas_per_co...|     1.5|coal_mine_depth|          0.752|   1.128|tonnes_coal_extra...|Tashan Coal Mine ...|Bituminous|POINT(113.047421 ...|\n",
      "|136113483|         CHN|              coal-mining|   null|co2e_100yr|         612588.83|               0|  tonnes_gas_per_co...|     1.5|coal_mine_depth|          0.752|   1.128|tonnes_coal_extra...|Tashan Coal Mine ...|Bituminous|POINT(113.047421 ...|\n",
      "|136113483|         CHN|              coal-mining|   null| co2e_20yr|        1695925.44|               0|  tonnes_gas_per_co...|     1.5|coal_mine_depth|          0.752|   1.128|tonnes_coal_extra...|Tashan Coal Mine ...|Bituminous|POINT(113.047421 ...|\n",
      "+---------+------------+-------------------------+-------+----------+------------------+----------------+----------------------+--------+---------------+---------------+--------+--------------------+--------------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['start_time', 'end_time', 'temporal_granularity','created_date','modified_date']\n",
    "\n",
    "coal_mining_df = dataframes[0].drop(*columns_to_drop)\n",
    "coal_mining_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|   asset_type|count|\n",
      "+-------------+-----+\n",
      "|      Lignite| 1160|\n",
      "|   Anthracite| 1325|\n",
      "|Subbituminous| 3170|\n",
      "|   Bituminous| 8125|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group by the 'Group' column and count occurrences\n",
    "coal_1 = coal_mining_df.groupBy(\"asset_type\").count().orderBy(\"count\", ascending=True)\n",
    "coal_1.show( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+----------+-------------------------+------------+------------------+----------------+--------+---------------+--------+\n",
      "|          asset_name|   asset_type|       gas|original_inventory_sector|iso3_country|emissions_quantity|emissions_factor|capacity|capacity_factor|activity|\n",
      "+--------------------+-------------+----------+-------------------------+------------+------------------+----------------+--------+---------------+--------+\n",
      "|     Gevra Coal Mine|Subbituminous|       co2|              coal-mining|         IND|               0.0|             0.0|    null|           null|    41.0|\n",
      "|Meihuajing Coal Mine|   Bituminous|co2e_100yr|              coal-mining|         CHN|        3805257.65|             0.0|    12.0|          0.752|   9.024|\n",
      "|Yujialiang Coal Mine|   Bituminous|       n2o|              coal-mining|         CHN|               0.0|             0.0|    13.0|          0.752|   9.776|\n",
      "|Jänschwalde Coal ...|      Lignite|       n2o|              coal-mining|         DEU|               0.0|             0.0|    null|           null|     9.1|\n",
      "|    Saraji Coal Mine|   Bituminous|       co2|              coal-mining|         AUS|               0.0|             0.0|    null|           null|     8.8|\n",
      "| Shubarkol Coal Mine|   Bituminous|       n2o|              coal-mining|         KAZ|               0.0|             0.0|    null|           null|     8.8|\n",
      "|Tweefontein Coal ...|   Bituminous|       ch4|              coal-mining|         ZAF|           32980.0|          3752.0|    null|           null|    8.79|\n",
      "|Chernogorsky Coal...|   Bituminous|       co2|              coal-mining|         RUS|               0.0|             0.0|    null|           null|    8.62|\n",
      "|Shaanxi Caojiatan...|   Bituminous| co2e_20yr|              coal-mining|         CHN|        7023126.53|             0.0|     8.0|          0.752|   6.016|\n",
      "|Hingula-II Coal Mine|      Lignite| co2e_20yr|              coal-mining|         IND|         327338.55|             0.0|    null|           null|    6.58|\n",
      "+--------------------+-------------+----------+-------------------------+------------+------------------+----------------+--------+---------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group by 'Asset_Group' and 'asset_type', calculate average of all values\n",
    "coal_2 = coal_mining_df.groupBy(\"asset_name\", \"asset_type\",\"gas\",\"original_inventory_sector\",\"iso3_country\").agg(\n",
    "        avg(col(\"emissions_quantity\")).alias(\"emissions_quantity\"),\n",
    "       avg(col(\"emissions_factor\")).alias(\"emissions_factor\"),\n",
    "        avg(col(\"capacity\")).alias(\"capacity\"),\n",
    "        avg(col(\"capacity_factor\")).alias(\"capacity_factor\"),\n",
    "        avg(col(\"activity\")).alias(\"activity\"),    \n",
    ")\n",
    "coal_2 = coal_2.dropna(subset=['emissions_quantity'])\n",
    "coal_2.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fossil Fuels - Oil and gas production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+-------------------------+----------+------------------+----------------+----------------------+----------+----------+--------------------+\n",
      "| asset_id|iso3_country|original_inventory_sector|       gas|emissions_quantity|emissions_factor|emissions_factor_units|asset_name|asset_type|           st_astext|\n",
      "+---------+------------+-------------------------+----------+------------------+----------------+----------------------+----------+----------+--------------------+\n",
      "|985525014|         BRA|     oil-and-gas-produ...|       co2|       1061964.698|     0.022535948|                  null|   Iracema|       Oil|POINT(-42.8345 -2...|\n",
      "|985525014|         BRA|     oil-and-gas-produ...|       ch4|        47032.6431|     0.000998079|                  null|   Iracema|       Oil|POINT(-42.8345 -2...|\n",
      "|985525014|         BRA|     oil-and-gas-produ...|       n2o|              null|            null|                  null|   Iracema|       Oil|POINT(-42.8345 -2...|\n",
      "|985525014|         BRA|     oil-and-gas-produ...|co2e_100yr|       2463537.462|            null|                  null|   Iracema|       Oil|POINT(-42.8345 -2...|\n",
      "|985525014|         BRA|     oil-and-gas-produ...| co2e_20yr|       5214982.886|            null|                  null|   Iracema|       Oil|POINT(-42.8345 -2...|\n",
      "+---------+------------+-------------------------+----------+------------------+----------------+----------------------+----------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['start_time', 'end_time', 'temporal_granularity','created_date','modified_date']\n",
    "\n",
    "coal_mining_df1 = dataframes[1].drop(*columns_to_drop)\n",
    "coal_mining_df1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|asset_type|count|\n",
      "+----------+-----+\n",
      "|       Gas| 7360|\n",
      "|       Oil|11935|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group by the 'Group' column and count occurrences\n",
    "oil_1 = coal_mining_df1.groupBy(\"asset_type\").count().orderBy(\"count\", ascending=True)\n",
    "oil_1.show( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+----------+----------+-------------------------+------------+------------------+--------------------+\n",
      "|asset_id|  asset_name|asset_type|       gas|original_inventory_sector|iso3_country|emissions_quantity|    emissions_factor|\n",
      "+--------+------------+----------+----------+-------------------------+------------+------------------+--------------------+\n",
      "| 5110213|     Ekofisk|       Oil|       ch4|     oil-and-gas-produ...|         NOR|20564.179999999997|5.097664285714285E-4|\n",
      "| 5110530|     Shengli|       Oil|co2e_100yr|     oil-and-gas-produ...|         CHN|1746821.2717142857|                null|\n",
      "| 5110532|Shwe Complex|       Gas|co2e_100yr|     oil-and-gas-produ...|         MMR|208388.22481428573|                null|\n",
      "| 5110466|    Pohokura|       Gas|       ch4|     oil-and-gas-produ...|         NZL|13724.184607571427|0.001277858428571...|\n",
      "| 5110320|      Keshen|       Gas| co2e_20yr|     oil-and-gas-produ...|         CHN| 9494147.830571428|                null|\n",
      "| 5110080|     Amistad|       Gas|co2e_100yr|     oil-and-gas-produ...|         ECU| 216615.3211142857|                null|\n",
      "| 5110310|         KMZ|       Oil|co2e_100yr|     oil-and-gas-produ...|         MEX|      1.35845856E7|                null|\n",
      "| 5110360|        Mahi|       Gas| co2e_20yr|     oil-and-gas-produ...|         CIV|366919.15075714287|                null|\n",
      "| 5110458|       Perla|       Gas|       ch4|     oil-and-gas-produ...|         VEN| 36296.23012271429|0.001573551142857...|\n",
      "| 5110501|       Sacha|       Oil|       co2|     oil-and-gas-produ...|         ECU| 1256086.142142857| 0.05010053071428572|\n",
      "+--------+------------+----------+----------+-------------------------+------------+------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group by 'Asset_Group' and 'asset_type', calculate average of all values\n",
    "oil_2 = coal_mining_df1.groupBy(\"asset_id\",\"asset_name\", \"asset_type\",\"gas\",\"original_inventory_sector\",\"iso3_country\").agg(\n",
    "        avg(col(\"emissions_quantity\")).alias(\"emissions_quantity\"),\n",
    "       avg(col(\"emissions_factor\")).alias(\"emissions_factor\"),\n",
    ")\n",
    "oil_2 = oil_2.dropna(subset=['emissions_quantity'])\n",
    "oil_2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder_dfs['fossil_fuel_operations_ownership_df'].show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_and_gas = oil_2.join(folder_dfs['fossil_fuel_operations_ownership_df'], ['asset_id', 'asset_name','original_inventory_sector'], 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oil_and_gas.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------------------------+--------------------+------------+---+------------------+--------------------+-----------------------+-------------------+----------+-----------+--------------------+\n",
      "|asset_id|asset_name|original_inventory_sector|              folder|iso3_country|gas|emissions_quantity|    emissions_factor|percentage_of_ownership|owner_direct_parent|asset_type| owner_name|      owner_grouping|\n",
      "+--------+----------+-------------------------+--------------------+------------+---+------------------+--------------------+-----------------------+-------------------+----------+-----------+--------------------+\n",
      "| 5110213|   Ekofisk|     oil-and-gas-produ...|fossil_fuel_opera...|         NOR|ch4|20564.179999999997|5.097664285714285E-4|                  12.39|Eni and HitecVision|       Oil|Vaar Energi|TotalEnergies; Co...|\n",
      "| 5110213|   Ekofisk|     oil-and-gas-produ...|fossil_fuel_opera...|         NOR|ch4|20564.179999999997|5.097664285714285E-4|                  12.39|Eni and HitecVision|       Oil|Vaar Energi|TotalEnergies; Co...|\n",
      "| 5110213|   Ekofisk|     oil-and-gas-produ...|fossil_fuel_opera...|         NOR|ch4|20564.179999999997|5.097664285714285E-4|                  12.39|Eni and HitecVision|       Oil|Vaar Energi|TotalEnergies; Co...|\n",
      "| 5110213|   Ekofisk|     oil-and-gas-produ...|fossil_fuel_opera...|         NOR|ch4|20564.179999999997|5.097664285714285E-4|                  12.39|Eni and HitecVision|       Oil|Vaar Energi|TotalEnergies; Co...|\n",
      "| 5110213|   Ekofisk|     oil-and-gas-produ...|fossil_fuel_opera...|         NOR|ch4|20564.179999999997|5.097664285714285E-4|                  12.39|Eni and HitecVision|       Oil|Vaar Energi|TotalEnergies; Co...|\n",
      "+--------+----------+-------------------------+--------------------+------------+---+------------------+--------------------+-----------------------+-------------------+----------+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select specific columns using col() function\n",
    "oil_and_gas_output = oil_and_gas.select(\n",
    "    col(\"asset_id\"),\n",
    "    col(\"asset_name\"),\n",
    "    col(\"original_inventory_sector\"),\n",
    "    col(\"folder\"),\n",
    "    col(\"iso3_country\"),\n",
    "    col(\"gas\"),\n",
    "    col(\"emissions_quantity\"),\n",
    "    col(\"emissions_factor\"),\n",
    "    col(\"percentage_of_ownership\"),\n",
    "    col(\"owner_direct_parent\"),\n",
    "    col(\"asset_type\"),\n",
    "    col(\"owner_name\"), \n",
    "    col(\"owner_grouping\")\n",
    ")\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "oil_and_gas_output.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_the_output(df_name):\n",
    "    num_files = 1  # Number of output files\n",
    "    df = globals().get(df_name)  # Get DataFrame by variable name\n",
    "    if df:\n",
    "        df.coalesce(num_files) \\\n",
    "            .write \\\n",
    "            .mode(\"append\") \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .csv(\"hdfs://localhost:9000/user/username/project_data/sector_output\")\n",
    "    else:\n",
    "        print(f\"DataFrame {df_name} not found.\")\n",
    "\n",
    "# Call the function for each DataFrame\n",
    "output_files = ['agriculture_df_3', 'agriculture_df_1', 'agriculture_df_2', 'grouped_avg_power', 'oil_and_gas_output', 'coal_2']\n",
    "for file in output_files:\n",
    "    store_the_output(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
